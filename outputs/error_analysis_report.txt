======================================================================
ERROR ANALYSIS REPORT
Comparative Analysis of Classification Errors (Section 4.5)
======================================================================


======================================================================
MODEL: 1_vader_generic
======================================================================

--- Class-wise Error Statistics (eq. 28-30) ---

  Class 'negative':
    True Positives (TP):  3
    False Positives (FP): 3
    False Negatives (FN): 416
    Precision: 0.5000
    Recall:    0.0072

  Class 'neutral':
    True Positives (TP):  100
    False Positives (FP): 1688
    False Negatives (FN): 0
    Precision: 0.0559
    Recall:    1.0000

  Class 'positive':
    True Positives (TP):  28
    False Positives (FP): 11
    False Negatives (FN): 1286
    Precision: 0.7179
    Recall:    0.0213

--- Misclassification Patterns ---
  negative -> neutral: 405 samples (96.7% of negative)
  negative -> positive: 11 samples (2.6% of negative)
  positive -> negative: 3 samples (0.2% of positive)
  positive -> neutral: 1283 samples (97.6% of positive)

  Most challenging class: 'positive' (1286 errors)

--- Sample Misclassified Texts ---

  Errors for 'negative':
    - "5 –æ–±—ñ—Ü—è–Ω–æ–∫ —è–∫—ñ –≤–∏ –ø–æ–≤–∏–Ω–Ω—ñ —Å–æ–±—ñ –¥–∞—Ç–∏"
      True: negative | Predicted: neutral
    - "@vadim_style @SergioS_2015 @peacein4rm @KarpenkoBatjar –ê —Ç–∏ –±–æ—è—Ä—É –∑ –¥–∏—Ç–∏–Ω—Å—Ç–≤–∞ –≥–ª..."
      True: negative | Predicted: neutral
    - "@nothingtodowth –ù—É –≤–æ—Ç –¥–∞ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –≤–∏—Ç—Ä–∞—Ç–∏ –Ω–∞ —ó–∂—É –π –ø—Å–∏—Ö–æ–ª–æ–≥—ñ—á–Ω–∞ –Ω–µ—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å..."
      True: negative | Predicted: neutral

  Errors for 'positive':
    - "–ü—Ä–æ—Å—Ç–æ –∑–∞–±–µ—Ä—ñ—Ç—å –º–µ–Ω–µ –∑–≤—ñ–¥—Å–∏. –ó–∞–∫—É—Ç–∞–π—Ç–µ —É –∫–æ–≤–¥—Ä–æ—á–∫—É. –û–±—ñ–π–º—ñ—Ç—å. –Ü –ø–æ–æ–±—ñ—Ü—è–π—Ç–µ. –©–æ –≤..."
      True: positive | Predicted: neutral
    - "@Cheschka –ë—É–ª–æ –± –¥–æ–±—Ä–µ –∞–ª–µ —Ü—å–æ–≥–æ —Ä–∞–∑—É –Ω–µ —Ü–∏—Ç–∞—Ç–∞ —É–≤–∏"
      True: positive | Predicted: neutral
    - "@n_biletska –ù—É —Å–Ω—ñ–≥ —Ä–æ–∑—Ç–∞–Ω—É–≤ —ñ —Ç–æ –¥–æ–±—Ä–µ))"
      True: positive | Predicted: neutral

======================================================================
MODEL: 2a_custom_ua_rulebased
======================================================================

--- Class-wise Error Statistics (eq. 28-30) ---

  Class 'negative':
    True Positives (TP):  305
    False Positives (FP): 176
    False Negatives (FN): 114
    Precision: 0.6341
    Recall:    0.7279

  Class 'neutral':
    True Positives (TP):  100
    False Positives (FP): 37
    False Negatives (FN): 0
    Precision: 0.7299
    Recall:    1.0000

  Class 'positive':
    True Positives (TP):  1119
    False Positives (FP): 96
    False Negatives (FN): 195
    Precision: 0.9210
    Recall:    0.8516

--- Misclassification Patterns ---
  negative -> neutral: 18 samples (4.3% of negative)
  negative -> positive: 96 samples (22.9% of negative)
  positive -> negative: 176 samples (13.4% of positive)
  positive -> neutral: 19 samples (1.4% of positive)

  Most challenging class: 'positive' (195 errors)

--- Sample Misclassified Texts ---

  Errors for 'negative':
    - "5 –æ–±—ñ—Ü—è–Ω–æ–∫ —è–∫—ñ –≤–∏ –ø–æ–≤–∏–Ω–Ω—ñ —Å–æ–±—ñ –¥–∞—Ç–∏"
      True: negative | Predicted: neutral
    - "@WowihaY –ê–≥–∞...—Ç–≤—ñ—Ç–æ—Ä –ø–∏—Ç–∏ –Ω–µ –¥–æ–∑–≤–æ–ª—è—î üòÖ –ê–ª–µ —â–æ—Å—å –≤—ñ–Ω –∑ –∑–∞–ø—ñ–∑–Ω–µ–Ω–Ω—è–º....—è –≤–∂–µ —ñ —Å..."
      True: negative | Predicted: positive
    - "–ü–æ-–¥—Ä—É–≥–µ –≤—ñ–Ω –ø—ñ—Å–ª—è —É—Ä–æ–∫ —Å–ø–∏—Ç–∞–≤ —á–∏ –º–µ–Ω—ñ –∑—Ä–æ–∑—É–º—ñ–ª–æ —è —Å–∫–∞–∑–∞–ª–∞ –∑–Ω–æ–≤—É —â–æ –º–æ–∑–æ–∫ –ø–æ–≥–∞–Ω–æ..."
      True: negative | Predicted: positive

  Errors for 'positive':
    - "–ü—Ä–æ—Å—Ç–æ –∑–∞–±–µ—Ä—ñ—Ç—å –º–µ–Ω–µ –∑–≤—ñ–¥—Å–∏. –ó–∞–∫—É—Ç–∞–π—Ç–µ —É –∫–æ–≤–¥—Ä–æ—á–∫—É. –û–±—ñ–π–º—ñ—Ç—å. –Ü –ø–æ–æ–±—ñ—Ü—è–π—Ç–µ. –©–æ –≤..."
      True: positive | Predicted: negative
    - "@leopolis31 –¥–æ–±—Ä–µ –º–æ–∂–ª–∏–≤–æ —Ü–µ –±–∞–≥ –Ω–∞–π–±–ª–∏–∂—á–∏–º —á–∞—Å–æ–º –≤–∏–ø—Ä–∞–≤–∏–º–æ. –ó –≤–µ–± –≤–µ—Ä—Å—ñ—ó –≤—Å–µ –≤ ..."
      True: positive | Predicted: negative
    - "–î–æ–±—Ä–µ —â–æ —Ç–µ–ª–µ–∫–∞–Ω–∞–ª–∏ –∫–ª–∏—á—É—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏—Ö –µ–∫—Å–ø–µ—Ä—Ç—ñ–≤ —ñ –ø—Ä–æ–∫–æ–º–µ–Ω—Ç—É–≤–∞—Ç–∏ –∫–æ–º–ø'—é—Ç–µ—Ä–Ω–∏–π ..."
      True: positive | Predicted: negative

======================================================================
MODEL: 2b_custom_ua_hybrid
======================================================================

--- Class-wise Error Statistics (eq. 28-30) ---

  Class 'negative':
    True Positives (TP):  411
    False Positives (FP): 40
    False Negatives (FN): 8
    Precision: 0.9113
    Recall:    0.9809

  Class 'neutral':
    True Positives (TP):  100
    False Positives (FP): 6
    False Negatives (FN): 0
    Precision: 0.9434
    Recall:    1.0000

  Class 'positive':
    True Positives (TP):  1270
    False Positives (FP): 6
    False Negatives (FN): 44
    Precision: 0.9953
    Recall:    0.9665

--- Misclassification Patterns ---
  negative -> neutral: 2 samples (0.5% of negative)
  negative -> positive: 6 samples (1.4% of negative)
  positive -> negative: 40 samples (3.0% of positive)
  positive -> neutral: 4 samples (0.3% of positive)

  Most challenging class: 'positive' (44 errors)

--- Sample Misclassified Texts ---

  Errors for 'negative':
    - "5 –æ–±—ñ—Ü—è–Ω–æ–∫ —è–∫—ñ –≤–∏ –ø–æ–≤–∏–Ω–Ω—ñ —Å–æ–±—ñ –¥–∞—Ç–∏"
      True: negative | Predicted: neutral
    - "–ß—É–¥–æ–≤–∞ —ñ–¥–µ—è —è–∫—É –ø—Ä–∏–¥—É–º–∞–ª–∏ —ñ—Ç–∞–ª—ñ–π—Ü—ñ."
      True: negative | Predicted: neutral
    - "–Ø–∫ —Å–∫–∞–∑–∞—Ç–∏ –ø—Ä–∞—Ü—ñ–≤–Ω–∏–∫—É —â–æ –≤—ñ–Ω —Å–º–µ—Ä–¥–∏—Ç—å? –Ü –Ω–µ –∑–±–∏—Ä–∞—é—Å—è —è –Ω–∞–∑–∏–≤–∞—Ç–∏ —Ü–µ —è–∫–∏–º–æ—Å—å —ñ–Ω—à–∏–º..."
      True: negative | Predicted: positive

  Errors for 'positive':
    - "–Ü–∑—é–º. –ü–ª–æ—â–∞ –õ–µ–Ω–Ω–æ–Ω–∞. –î–æ–±—Ä–µ! –ü–æ–≥–∞–Ω–æ —â–æ –Ω–µ –≤–∏–π—à–ª–æ —â–µ –≤ –•–∞—Ä–∫–æ–≤—ñ. –ê–ª–µ —è —É—è–≤–ª—è—é —â–æ –±—É..."
      True: positive | Predicted: negative
    - "@yadrobotun –ú–∞–±—É—Ç—å —á–æ–ª–æ–≤—ñ—á–µ —ñ –∂—ñ–Ω–æ—á–µ –≤—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è –≤ –°–Ü–ó–û –Ω–µ —Å–ø–æ–ª—É—á–∞—é—Ç—å—Å—è. –ê–ª–µ —Ü–µ —è..."
      True: positive | Predicted: negative
    - "–ú–µ–Ω—ñ –Ω–∞–ø—Ä–∏–∫–ª–∞–¥ –Ω–∞—á—Ö–∞—Ç–∏ –Ω–∞ —Å–∫—ñ–ª—å–∫–∏ –º—ñ–ª—å—è—Ä–¥—ñ–≤ "–£–∫—Ä–æ–±–æ—Ä–æ–Ω–ø—Ä–æ–º" –ø—Ä–æ–¥–∞–≤ "–ë—É–ª–∞—Ç—ñ–≤" —Ç–∞ ..."
      True: positive | Predicted: negative

======================================================================
MODEL: 3_tfidf_logreg
======================================================================

--- Class-wise Error Statistics (eq. 28-30) ---

  Class 'negative':
    True Positives (TP):  414
    False Positives (FP): 31
    False Negatives (FN): 5
    Precision: 0.9303
    Recall:    0.9881

  Class 'neutral':
    True Positives (TP):  100
    False Positives (FP): 0
    False Negatives (FN): 0
    Precision: 1.0000
    Recall:    1.0000

  Class 'positive':
    True Positives (TP):  1283
    False Positives (FP): 5
    False Negatives (FN): 31
    Precision: 0.9961
    Recall:    0.9764

--- Misclassification Patterns ---
  negative -> positive: 5 samples (1.2% of negative)
  positive -> negative: 31 samples (2.4% of positive)

  Most challenging class: 'positive' (31 errors)

--- Sample Misclassified Texts ---

  Errors for 'negative':
    - "–ó –ê–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ü—ñ—ó –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –ü–µ—Ç—Ä–æ –ü–æ—Ä–æ—à–µ–Ω–∫–æ –Ω–∞–¥—ñ–π—à–ª–∞ –∫–æ–º–∞–Ω–¥–∞ –≥–µ–Ω–ø—Ä–æ–∫—É—Ä–æ—Ä—É –Æ—Ä—ñ–π –õ—É..."
      True: negative | Predicted: positive
    - "–ù–∞–º —â–∞—Å—Ç–∏–ª–æ —ñ–∑ —Ç–∞–∫—Å–∏—Å—Ç–∞–º–∏ –≤–æ–ª–æ–Ω—Ç–µ—Ä–∞–º–∏ —ñ –∫—Ä–∞—î–≤–∏–¥–∞–º–∏Ôºõ –¥–≤—ñ –±–æ–ª–≥–∞—Ä–∫–∏ –Ω–∞–∑–≤–∞–ª–∏ –Ω–∞—Å –¥–∏–≤..."
      True: negative | Predicted: positive
    - "@Magellan_Fernan @Gal_linochka @putina_v_Gaagu @LyapunovS –¶–µ –¥–æ–±—Ä–µ,–∞–ª–µ –º–æ–∂—É—Ç—å —ñ ..."
      True: negative | Predicted: positive

  Errors for 'positive':
    - "–Ü–∑—é–º. –ü–ª–æ—â–∞ –õ–µ–Ω–Ω–æ–Ω–∞. –î–æ–±—Ä–µ! –ü–æ–≥–∞–Ω–æ —â–æ –Ω–µ –≤–∏–π—à–ª–æ —â–µ –≤ –•–∞—Ä–∫–æ–≤—ñ. –ê–ª–µ —è —É—è–≤–ª—è—é —â–æ –±—É..."
      True: positive | Predicted: negative
    - "@yadrobotun –ú–∞–±—É—Ç—å —á–æ–ª–æ–≤—ñ—á–µ —ñ –∂—ñ–Ω–æ—á–µ –≤—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è –≤ –°–Ü–ó–û –Ω–µ —Å–ø–æ–ª—É—á–∞—é—Ç—å—Å—è. –ê–ª–µ —Ü–µ —è..."
      True: positive | Predicted: negative
    - "–û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–æ —ò–µ –∞–∫—Ü–∏—ò—É –∑–∞ –º–æ—ò—É –ø—Ä–∏—ò–∞—Ç–µ—ô–∏—Ü—É –ú–∏–ª–∞–Ω—É –ì–∞—ò–∏—õ –∏ —Å—Ä–µ–¥—Å—Ç–≤–∞ –Ω–∏–∫–∞–¥–∞ –Ω–∏—Å—É –¥–æ..."
      True: positive | Predicted: negative

======================================================================
MODEL: 4_xlm-roberta-base
======================================================================

--- Class-wise Error Statistics (eq. 28-30) ---

  Class 'negative':
    True Positives (TP):  416
    False Positives (FP): 41
    False Negatives (FN): 3
    Precision: 0.9103
    Recall:    0.9928

  Class 'neutral':
    True Positives (TP):  100
    False Positives (FP): 1
    False Negatives (FN): 0
    Precision: 0.9901
    Recall:    1.0000

  Class 'positive':
    True Positives (TP):  1272
    False Positives (FP): 3
    False Negatives (FN): 42
    Precision: 0.9976
    Recall:    0.9680

--- Misclassification Patterns ---
  negative -> positive: 3 samples (0.7% of negative)
  positive -> negative: 41 samples (3.1% of positive)
  positive -> neutral: 1 samples (0.1% of positive)

  Most challenging class: 'positive' (42 errors)

--- Sample Misclassified Texts ---

  Errors for 'negative':
    - "–º–µ–Ω—ñ –Ω–µ –ø–æ–≥–∞–Ω–æ —ñ –Ω–µ –¥–æ–±—Ä–µ –º–µ–Ω—ñ —è–∫–æ—Å—å –Ω—ñ—è–∫"
      True: negative | Predicted: positive
    - "–î—É—Ö–æ–≤–Ω–∏–π —Å—Ç–∞–Ω –ª—é–¥–∏–Ω–∏ –∫—Ä–∞—â–µ –≤–∏—è–≤–ª—è—î—Ç—å—Å—è –Ω–µ —Ç–æ–¥—ñ –∫–æ–ª–∏ —ó–π –ø–æ–≥–∞–Ω–æ –∞ —Ç–æ–¥—ñ –∫–æ–ª–∏ —ó–π –¥–æ–±..."
      True: negative | Predicted: positive
    - "–ó–∞–≤–∂–¥–∏ —Ä–∞–¥—ñ—é –∫–æ–ª–∏ –æ—Ç—Ä–∏–º—É—é —É–≤–∞–≥—É –∑–ª–æ—á–∏–Ω–Ω–æ—ó –≤–ª–∞–¥–∏! –®–∫–æ–¥–∞ —â–æ —Å—Ä–∞—á —Ç—É—Ç –æ—Å–æ–±–ª–∏–≤–∏–π –Ω–µ ..."
      True: negative | Predicted: positive

  Errors for 'positive':
    - "–Ü–∑—é–º. –ü–ª–æ—â–∞ –õ–µ–Ω–Ω–æ–Ω–∞. –î–æ–±—Ä–µ! –ü–æ–≥–∞–Ω–æ —â–æ –Ω–µ –≤–∏–π—à–ª–æ —â–µ –≤ –•–∞—Ä–∫–æ–≤—ñ. –ê–ª–µ —è —É—è–≤–ª—è—é —â–æ –±—É..."
      True: positive | Predicted: negative
    - "–ü–µ—Ç—Ä–æ –ü–æ—Ä–æ—à–µ–Ω–∫–æ –≤–∞–º –ø–æ–¥–æ–±–∞—î—Ç—å—Å—è —Ç–∞–∫–µ —Å—Ç–∞–≤–ª–µ–Ω–Ω—è –¥–æ –¥—ñ–∞–±–µ—Ç–∏–∫—ñ–≤? __ –ü–µ—Ç—Ä–æ –ü–æ—Ä–æ—à–µ–Ω–∫–æ..."
      True: positive | Predicted: negative
    - "@yadrobotun –ú–∞–±—É—Ç—å —á–æ–ª–æ–≤—ñ—á–µ —ñ –∂—ñ–Ω–æ—á–µ –≤—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è –≤ –°–Ü–ó–û –Ω–µ —Å–ø–æ–ª—É—á–∞—é—Ç—å—Å—è. –ê–ª–µ —Ü–µ —è..."
      True: positive | Predicted: negative

======================================================================
MODEL: 5_bert-base-multilingual-cased
======================================================================

--- Class-wise Error Statistics (eq. 28-30) ---

  Class 'negative':
    True Positives (TP):  415
    False Positives (FP): 57
    False Negatives (FN): 4
    Precision: 0.8792
    Recall:    0.9905

  Class 'neutral':
    True Positives (TP):  100
    False Positives (FP): 1
    False Negatives (FN): 0
    Precision: 0.9901
    Recall:    1.0000

  Class 'positive':
    True Positives (TP):  1257
    False Positives (FP): 3
    False Negatives (FN): 57
    Precision: 0.9976
    Recall:    0.9566

--- Misclassification Patterns ---
  negative -> neutral: 1 samples (0.2% of negative)
  negative -> positive: 3 samples (0.7% of negative)
  positive -> negative: 57 samples (4.3% of positive)

  Most challenging class: 'positive' (57 errors)

--- Sample Misclassified Texts ---

  Errors for 'negative':
    - "5 –æ–±—ñ—Ü—è–Ω–æ–∫ —è–∫—ñ –≤–∏ –ø–æ–≤–∏–Ω–Ω—ñ —Å–æ–±—ñ –¥–∞—Ç–∏"
      True: negative | Predicted: neutral
    - "–ù–µ—Å–µ –í—ñ–∫–∞ –≤–æ–¥—É –ø—Ä—è–º–æ –∑ –ø—ñ–¥ –∫–∞—à—Ç–∞–Ω—É –∞ –≤—ñ–¥ –Ω–µ—ó –∑–∞–ø–∞—à–æ–∫ —à–æ –∞–∂ –≤—Å—ñ–º –ø–æ–≥–∞–Ω–æüòÇüòÇ"
      True: negative | Predicted: positive
    - "–¢–∞–∫ –Ω–µ–∑—Ä—É—á–Ω–æ –∫–æ–ª–∏ —Ç–∏ –ø—Ä–æ—Å—Ç–æ —Å–∏–¥–∏—à –Ω–∞ —Å—Ö–æ–¥–∞—Ö –¥–ª—è –≤–¥–∞–ª–æ–≥–æ –∫–∞–¥—Ä—É,—É –º–µ—Ç—Ä–æ,—Ü–µ –≤—Å–µ –∑–Ω—ñ..."
      True: negative | Predicted: positive

  Errors for 'positive':
    - "–Ü–∑—é–º. –ü–ª–æ—â–∞ –õ–µ–Ω–Ω–æ–Ω–∞. –î–æ–±—Ä–µ! –ü–æ–≥–∞–Ω–æ —â–æ –Ω–µ –≤–∏–π—à–ª–æ —â–µ –≤ –•–∞—Ä–∫–æ–≤—ñ. –ê–ª–µ —è —É—è–≤–ª—è—é —â–æ –±—É..."
      True: positive | Predicted: negative
    - "–ü–µ—Ç—Ä–æ –ü–æ—Ä–æ—à–µ–Ω–∫–æ –≤–∞–º –ø–æ–¥–æ–±–∞—î—Ç—å—Å—è —Ç–∞–∫–µ —Å—Ç–∞–≤–ª–µ–Ω–Ω—è –¥–æ –¥—ñ–∞–±–µ—Ç–∏–∫—ñ–≤? __ –ü–µ—Ç—Ä–æ –ü–æ—Ä–æ—à–µ–Ω–∫–æ..."
      True: positive | Predicted: negative
    - "@yadrobotun –ú–∞–±—É—Ç—å —á–æ–ª–æ–≤—ñ—á–µ —ñ –∂—ñ–Ω–æ—á–µ –≤—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è –≤ –°–Ü–ó–û –Ω–µ —Å–ø–æ–ª—É—á–∞—é—Ç—å—Å—è. –ê–ª–µ —Ü–µ —è..."
      True: positive | Predicted: negative


======================================================================
CROSS-MODEL ERROR SUMMARY
======================================================================

Neutral class error rates (most challenging category):
  1_vader_generic: 0/100 errors (0.0%)
  2a_custom_ua_rulebased: 0/100 errors (0.0%)
  2b_custom_ua_hybrid: 0/100 errors (0.0%)
  3_tfidf_logreg: 0/100 errors (0.0%)
  4_xlm-roberta-base: 0/100 errors (0.0%)
  5_bert-base-multilingual-cased: 0/100 errors (0.0%)

======================================================================
Key findings aligned with Section 4.5:
- Rule-based: systematic errors due to static lexicons
- Classical ML: errors in long-range dependencies
- Transformers: more balanced, but struggle with neutral/ambiguous
======================================================================